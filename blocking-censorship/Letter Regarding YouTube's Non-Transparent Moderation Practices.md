Letter Regarding YouTube's Non-Transparent Moderation Practices
To the attention of the European Commission and those responsible for enforcing the Digital Services Act

We, digital researchers, content creators, and human rights defenders, are submitting this letter as a formal complaint regarding YouTube's non-transparent content moderation practices, which appear to disproportionately impact freedom of expression, especially in the areas of:

    Political satire

    Academic analysis

    Content related to war, censorship, and repression

Please be advised that this letter is being sent to the relevant authorities for investigation and will be submitted alongside YouTube’s response to our appeal, which was unsatisfactory and did not address the key issues at hand.
Identified Violations

    Content Removal Without Explanation or Warning

        YouTube removes videos or entire channels without providing clear reasons or documentation of platform policy violations. Users are frequently left without the ability to understand which specific rule was violated.

    Use of Automated Systems Without the Ability to Appeal

        Automated moderation systems often make decisions regarding content removal without human intervention, making it impossible for users to contest these decisions, particularly in cases of false or unjustified blockings.

    Removal of Channels Without Clear Policy Violations

        Channels that publish political satire or criticize government actions are frequently removed without clear reasoning. This undermines the right to free expression, especially in the context of political criticism.

    Lack of Tools to Verify the Justification of Decisions

        Users do not have the ability to verify the criteria or reasoning behind content removal, which undermines the principles of transparency and fairness in the digital environment.

    "Algorithmic Responsibility" Mechanisms Replacing Legal Accountability

        Algorithms that make content removal decisions are not subject to transparent review mechanisms, which violates the principles of independent moderation systems defined under the DSA.

Examples of Violations

    Political Satire Channels: Channels that publish political satire without hate speech have been repeatedly removed without explanation. For instance, one channel critical of authoritarian regimes was deleted despite adhering to YouTube's guidelines, violating the principle of freedom of expression.

    Veterans' and Volunteer Blogs: Videos documenting the realities of war often receive "shock content" labels despite following YouTube's guidelines. This limits the ability to share personal experiences and honest reflections about conflict.

    Academic Materials on Disinformation: Videos and articles examining disinformation and media manipulation are labeled as "manipulative" and blocked, despite presenting factual, research-based content.

Legislative Framework

The Digital Services Act (DSA), which came into effect in 2023, mandates the following:

    Transparency of Platform Decisions: Users must be able to receive clear explanations for content moderation decisions.

    Right to Appeal: Users should have a mechanism to appeal content removal decisions.

    Clear Criteria for "Harmful Content": Platforms must clearly define what constitutes harmful content and specify the grounds for its removal.

    Independent Audit of Moderation Systems: Since content moderation can have significant implications on free expression, an independent audit of YouTube's moderation systems is required to ensure fairness.

However, YouTube is not adequately providing these mechanisms, violating the requirements of the DSA.
Our Demands

    Conduct an Audit of YouTube's Moderation System in accordance with the DSA, involving independent organizations.

    Provide Feedback When Content is Removed and allow users to receive clear explanations regarding the violations.

    Implement an Appeal Mechanism for automated decisions, enabling users to challenge wrongful or unjustified content removals.

    Ensure Political Neutrality in Algorithms: YouTube must ensure that its content moderation algorithms remain neutral and do not discriminate against political or ideological positions.

Conclusion

    Freedom of expression should not be lost under the guise of "undesirable content" classification. We must have access to an open platform for exchanging ideas and information.

This letter is part of a public initiative aimed at preserving digital rights in the era of automated censorship.

Sincerely,  Yedamenko Kostyantyn  
Email for contact: kos75@proton.me
Email linked to affected YouTube account: yedamenko@gmail.com